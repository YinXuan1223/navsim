{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19eaca7b",
   "metadata": {},
   "source": [
    "## Ë®òÈåÑ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b7a26f",
   "metadata": {},
   "source": [
    "ÁõÆÂâçÈÄ≤Â∫¶Ôºö\n",
    "1. Ê≠£Â∏∏ËÆì code Ë∑ëËµ∑‰æÜ„ÄÇ\n",
    "2. ‰øÆÊîπ filterÔºåËÆìÊâÄÊúâ frame Ëº∏Âá∫„ÄÇ\n",
    "3. ËôïÁêÜ stage 2 ground truth ÁöÑÂïèÈ°å„ÄÇ\n",
    "4. Âä†‰∏ÄÂÄã python Ê™îÔºåËÆì‰ªñÂèØ‰ª•Âπ´ÊàëÂÄëÊääÈÄ£Á∫åÁöÑ frame ÊîæÂú®Âêå‰∏ÄÂÄãË≥áÊñôÂ§æ„ÄÇ\n",
    "5. Ë®àÁÆó ground truth ÁöÑ pdm score ** comfort\n",
    "\n",
    "ÂæÖËæ¶‰∫ãÈ†ÖÔºö\n",
    "1. ÁúãÈù†Ëøë ground truth ÁöÑË∑ØÁ∑öÁöÑÂàÜÊï∏"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c1e64d",
   "metadata": {},
   "source": [
    "## Import and Def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75bd683e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Script to save BEV visualizations for different token categories\n",
    "Based on the analysis from plot_result.ipynb\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "import hydra\n",
    "from hydra.utils import instantiate\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from typing import Any, Dict, List, Tuple\n",
    "from tqdm import tqdm\n",
    "import lzma\n",
    "# Add the GTRS root to path\n",
    "sys.path.append('/mnt/hdd5/Qiaoceng/navsim_workspace/GTRS')\n",
    "\n",
    "from navsim.common.dataloader import SceneLoader\n",
    "from navsim.common.dataclasses import SceneFilter, SensorConfig\n",
    "from nuplan.common.actor_state.state_representation import TimePoint\n",
    "from navsim.visualization.bev import add_configured_bev_on_ax, add_trajectory_to_bev_ax\n",
    "from navsim.visualization.plots import configure_bev_ax, configure_ax\n",
    "from navsim.visualization.config import TRAJECTORY_CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c66d2ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_environment():\n",
    "    \"\"\"Set up environment variables and load configurations\"\"\"\n",
    "    # Set environment variables explicitly\n",
    "    os.environ[\"NUPLAN_MAPS_ROOT\"] = \"/mnt/hdd8/navsim_dataset/maps\"\n",
    "    os.environ[\"NUPLAN_MAP_VERSION\"] = \"nuplan-maps-v1.0\"\n",
    "    os.environ[\"NUPLAN_DATA_STORE\"] = \"local\"\n",
    "    os.environ[\"OPENSCENE_DATA_ROOT\"] = \"/mnt/hdd8/navsim_dataset\"\n",
    "    os.environ[\"NAVSIM_EXP_ROOT\"] = \"/mnt/hdd5/Qiaoceng/navsim_workspace/exp\"\n",
    "    os.environ[\"NAVSIM_DEVKIT_ROOT\"] = \"/mnt/hdd5/Qiaoceng/navsim_workspace/GTRS\"\n",
    "\n",
    "    load_dotenv(override=True)\n",
    "    \n",
    "    print(\"Environment variables set successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28a708c",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3485938061.py, line 27)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[3], line 27\u001b[0;36m\u001b[0m\n\u001b[0;31m    /mnt/hdd8/navsim_dataset/navhard_two_stage/sensor_blobs,\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def load_data():\n",
    "    \"\"\"Load all required data and configurations\"\"\"\n",
    "    \n",
    "    # Also set the nuplan constants directly\n",
    "    import nuplan.common.maps.nuplan_map.map_factory as map_factory\n",
    "    map_factory.NUPLAN_MAPS_ROOT = \"/mnt/hdd8/navsim_dataset/maps\"\n",
    "    \n",
    "    # Print for debugging\n",
    "    print(f\"NUPLAN_MAPS_ROOT: {os.environ.get('NUPLAN_MAPS_ROOT')}\")\n",
    "    print(f\"OPENSCENE_DATA_ROOT: {os.environ.get('OPENSCENE_DATA_ROOT')}\")\n",
    "    \n",
    "    # Constants for data configuration\n",
    "    DATA_SPLIT = \"test\"\n",
    "    SCENE_FILTER_NAME = \"navhard_two_stage\"\n",
    "    \n",
    "    # Initialize Hydra configuration for scene filtering\n",
    "    hydra.initialize(config_path=\"../navsim/planning/script/config/common/train_test_split/scene_filter\", version_base=None)\n",
    "    scene_filter_config = hydra.compose(config_name=SCENE_FILTER_NAME)\n",
    "    scene_filter: SceneFilter = instantiate(scene_filter_config)\n",
    "    \n",
    "    # Setup data paths\n",
    "    openscene_data_root = Path(os.getenv(\"OPENSCENE_DATA_ROOT\"))\n",
    "    navhard_scene_loader = SceneLoader(\n",
    "        openscene_data_root / f\"navsim_logs/{DATA_SPLIT}\",\n",
    "        openscene_data_root / f\"sensor_blobs/{DATA_SPLIT}\",\n",
    "        scene_filter,\n",
    "        \"/mnt/hdd8/navsim_dataset/navhard_two_stage/sensor_blobs\",\n",
    "        \"/mnt/hdd8/navsim_dataset/navhard_two_stage/synthetic_scene_pickles\",\n",
    "        sensor_config=SensorConfig.build_no_sensors(),\n",
    "    )\n",
    "    \n",
    "    # Load GTRS Dense model predictions\n",
    "    gtrs_dense_model_path = '/mnt/hdd5/Qiaoceng/navsim_workspace/model/GTRS/epoch19_navhard.pkl'\n",
    "    with open(gtrs_dense_model_path, 'rb') as f:\n",
    "        gtrs_dense_model_predictions = pickle.load(f)\n",
    "    \n",
    "    # Load trajectory vocabulary\n",
    "    trajectory_vocab_path = '/mnt/hdd5/Qiaoceng/navsim_workspace/GTRS/traj_final/8192.npy'\n",
    "    trajectory_vocabulary = np.load(trajectory_vocab_path)\n",
    "    \n",
    "    # Load evaluation results\n",
    "    evaluation_results_path = \"/mnt/hdd5/Qiaoceng/navsim_workspace/exp/train_gtrs_dense/2025.08.21.17.44.36/2025.08.21.18.36.35.csv\"\n",
    "    evaluation_results_df = pd.read_csv(evaluation_results_path)\n",
    "    \n",
    "    # Load submission file\n",
    "    submission_file_path = \"/mnt/hdd5/Qiaoceng/navsim_workspace/model/GTRS/submission_gtrs_dense.pkl\"\n",
    "    with open(submission_file_path, \"rb\") as f:\n",
    "        submission_predictions = pickle.load(f)\n",
    "    \n",
    "    return (navhard_scene_loader, gtrs_dense_model_predictions, trajectory_vocabulary, \n",
    "            evaluation_results_df, submission_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb1825d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_scores(result):\n",
    "    \"\"\"Calculate trajectory scores\"\"\"\n",
    "    time_to_collision_within_bound = np.exp(result['time_to_collision_within_bound'])\n",
    "    ego_progress = np.exp(result['ego_progress'])\n",
    "    lane_keeping = np.exp(result['lane_keeping'])\n",
    "    scores = (\n",
    "        0.01 * result['imi'] +\n",
    "        0.1 * result['traffic_light_compliance'] +\n",
    "        0.5 * result['no_at_fault_collisions'] +\n",
    "        0.5 * result['drivable_area_compliance'] +\n",
    "        0.5 * result['driving_direction_compliance'] +\n",
    "        3.0 * np.log(5.0 * time_to_collision_within_bound +\n",
    "                    5.0 * ego_progress +\n",
    "                    2.0 * lane_keeping)\n",
    "    )\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dca58e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_score(scores):\n",
    "    \"\"\"Normalize trajectory scores\"\"\"\n",
    "    scores = np.where(np.isfinite(scores), scores, np.nan)\n",
    "    if np.all(np.isnan(scores)):\n",
    "        return np.zeros_like(scores)\n",
    "    min_score = np.nanmin(scores)\n",
    "    max_score = np.nanmax(scores)\n",
    "    if max_score == min_score:\n",
    "        return np.zeros_like(scores)\n",
    "    norm = (scores - min_score) / (max_score - min_score)\n",
    "    norm = np.nan_to_num(norm, nan=0.0)\n",
    "    return norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8def4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trajectory_predictions_for_token(token: str, trajectory_vocabulary, gtrs_dense_model_predictions) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"Get sorted trajectory predictions for a token\"\"\"\n",
    "    total_trajectory = np.concatenate((trajectory_vocabulary, gtrs_dense_model_predictions[token]['interpolated_proposal']), axis=0)\n",
    "    \n",
    "    scores = calculate_scores(gtrs_dense_model_predictions[token])\n",
    "    weights = normalize_score(scores)\n",
    "    sorted_indices = np.argsort(weights)[::-1]\n",
    "    sorted_trajectories = total_trajectory[sorted_indices]\n",
    "    sorted_weights = weights[sorted_indices]\n",
    "    \n",
    "    return sorted_trajectories, sorted_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09a6cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function for 1. Stage 2 reference trajectory\n",
    "\n",
    "def get_stage2_reference_trajectory(scene_loader, token: str):\n",
    "    try:\n",
    "        scene = scene_loader.get_scene_from_token(token)\n",
    "        \n",
    "        # Determine if it is Stage 2 - if there is corresponding_original_initial_token, it is Stage 2\n",
    "        if not hasattr(scene.scene_metadata, 'corresponding_original_initial_token') or \\\n",
    "           scene.scene_metadata.corresponding_original_initial_token is None:\n",
    "            return None \n",
    "            \n",
    "        log_name = scene.scene_metadata.log_name\n",
    "        timestamp = scene.frames[scene.scene_metadata.num_history_frames - 1].timestamp\n",
    "\n",
    "        ## Extract reference trajectory from metric cache\n",
    "        # Construct metric cache path - use more precise search\n",
    "        stage2_cache_path = Path('/mnt/hdd5/Qiaoceng/navsim_workspace/exp/metric_cache_stage_2')\n",
    "        \n",
    "        # Search for corresponding cache file - match using log_name\n",
    "        cache_file = None\n",
    "        for scene_dir in stage2_cache_path.iterdir():\n",
    "            if scene_dir.is_dir() and log_name in scene_dir.name:\n",
    "                for sub_dir in scene_dir.rglob('*'):\n",
    "                    if sub_dir.is_dir():\n",
    "                        pkl_file = sub_dir / 'metric_cache.pkl'\n",
    "                        if pkl_file.exists():\n",
    "                            try:  # Validate if it is the correct cache\n",
    "                                with lzma.open(pkl_file, 'rb') as f:\n",
    "                                    metric_cache = pickle.load(f)\n",
    "                                if (hasattr(metric_cache, 'log_name') and  # Check if log_name and timestamp match\n",
    "                                    metric_cache.log_name == log_name and\n",
    "                                    hasattr(metric_cache, 'timepoint')):\n",
    "                                    # Simple time matching check\n",
    "                                    cache_time = metric_cache.timepoint.time_s\n",
    "                                    scene_time = timestamp / 1e6  # Convert to seconds\n",
    "                                    if abs(cache_time - scene_time) < 1.0:  # 1 second tolerance\n",
    "                                        cache_file = pkl_file\n",
    "                                        break\n",
    "                            except:\n",
    "                                continue\n",
    "                if cache_file:\n",
    "                    break\n",
    "        \n",
    "        if not cache_file:\n",
    "            print(f\"No corresponding cache file found for token: {token}\")\n",
    "            return None\n",
    "            \n",
    "        # ËÆÄÂèñ‰∏¶ËôïÁêÜËªåË∑°\n",
    "        with lzma.open(cache_file, 'rb') as f:\n",
    "            metric_cache = pickle.load(f)\n",
    "        \n",
    "        traj = metric_cache.trajectory\n",
    "        if not traj:\n",
    "            return None\n",
    "        \n",
    "        # Êé°Ê®£ËªåË∑°Èªû - ÂæûÁï∂ÂâçÊôÇÈñìÈªûÈñãÂßãÊé°Ê®£\n",
    "        start_time_us = traj.start_time.time_us\n",
    "        end_time_us = traj.end_time.time_us\n",
    "        current_time_us = timestamp * 1e6\n",
    "        \n",
    "        # ÊâæÂà∞ËàáÁï∂ÂâçÂ†¥ÊôØÊôÇÈñìÊúÄÊé•ËøëÁöÑËªåË∑°Ëµ∑ÂßãÈªû\n",
    "        search_range_us = 2.0 * 1e6  # ÊêúÁ¥¢ÁØÑÂúçÔºöÂâçÂæå2Áßí\n",
    "        search_start = max(start_time_us, current_time_us - search_range_us)\n",
    "        search_end = min(end_time_us, current_time_us + search_range_us)\n",
    "        \n",
    "        min_time_diff = float('inf')\n",
    "        best_start_time_us = None\n",
    "        \n",
    "        for test_time_us in range(int(search_start), int(search_end), int(0.1 * 1e6)):\n",
    "            time_diff = abs(test_time_us - current_time_us)\n",
    "            if time_diff < min_time_diff:\n",
    "                min_time_diff = time_diff\n",
    "                best_start_time_us = test_time_us\n",
    "        \n",
    "        if best_start_time_us is None:\n",
    "            best_start_time_us = start_time_us\n",
    "        \n",
    "        # ÊØè 0.5 ÁßíÊé°Ê®£‰∏ÄÊ¨°ÔºåÁ∏ΩÂÖ± 4 ÁßíÔºà8ÂÄãÈªûÔºâ\n",
    "        sample_interval_us = int(0.5 * 1e6)\n",
    "        \n",
    "        time_points = []\n",
    "        for i in range(8):  # 8ÂÄãÈªû\n",
    "            time_us = best_start_time_us + i * sample_interval_us\n",
    "            if time_us <= end_time_us:\n",
    "                time_points.append(TimePoint(time_us))\n",
    "            else:\n",
    "                break\n",
    "        \n",
    "        # Áç≤ÂèñÊØèÂÄãÊôÇÈñìÈªûÁöÑÁãÄÊÖã\n",
    "        states = []\n",
    "        for time_point in time_points:\n",
    "            try:\n",
    "                state = traj.get_state_at_time(time_point)\n",
    "                states.append(state)\n",
    "            except:\n",
    "                break\n",
    "        \n",
    "        if len(states) < 2:\n",
    "            return None\n",
    "            \n",
    "        # Áç≤ÂèñÁï∂ÂâçÂ†¥ÊôØÁöÑ ego Ëµ∑Âßã‰ΩçÁΩÆ\n",
    "        current_ego_state = scene.frames[scene.scene_metadata.num_history_frames - 1].ego_status.ego_pose\n",
    "        \n",
    "        # Áç≤ÂèñÁï∂Ââç ego ‰ΩçÁΩÆÁöÑ x, y, heading ÂùêÊ®ô\n",
    "        if hasattr(current_ego_state, 'x') and hasattr(current_ego_state, 'y'):\n",
    "            ego_x, ego_y = current_ego_state.x, current_ego_state.y\n",
    "            ego_heading = current_ego_state.heading if hasattr(current_ego_state, 'heading') else 0.0\n",
    "        elif isinstance(current_ego_state, np.ndarray):\n",
    "            ego_x, ego_y = current_ego_state[0], current_ego_state[1]\n",
    "            ego_heading = current_ego_state[2] if len(current_ego_state) > 2 else 0.0\n",
    "        else:\n",
    "            ego_x, ego_y = current_ego_state[0], current_ego_state[1]\n",
    "            ego_heading = current_ego_state[2] if len(current_ego_state) > 2 else 0.0\n",
    "        \n",
    "        # ËΩâÊèõÁÇ∫Áõ∏Â∞çÊñºÁï∂Ââç ego ‰ΩçÁΩÆÁöÑËªåË∑°ÔºàÂ±ÄÈÉ®Â∫ßÊ®ôÁ≥ªÔºâ\n",
    "        positions = []\n",
    "        for i, state in enumerate(states):\n",
    "            try:\n",
    "                # Áç≤ÂèñËªåË∑°ÈªûÁöÑÁµïÂ∞çÂ∫ßÊ®ô\n",
    "                if hasattr(state, 'rear_axle') and hasattr(state.rear_axle, 'x'):\n",
    "                    traj_x = state.rear_axle.x\n",
    "                    traj_y = state.rear_axle.y\n",
    "                elif hasattr(state, 'x') and hasattr(state, 'y'):\n",
    "                    traj_x = state.x\n",
    "                    traj_y = state.y\n",
    "                elif isinstance(state, np.ndarray):\n",
    "                    traj_x = state[0]\n",
    "                    traj_y = state[1]\n",
    "                else:\n",
    "                    continue\n",
    "                \n",
    "                # Ë®àÁÆóÁõ∏Â∞çÊñº ego ÁöÑÂÅèÁßªÔºàÂÖ®Â±ÄÂ∫ßÊ®ôÁ≥ªÔºâ\n",
    "                dx = traj_x - ego_x\n",
    "                dy = traj_y - ego_y\n",
    "                \n",
    "                # ËΩâÊèõÂà∞‰ª• ego ÁÇ∫ÂéüÈªûÔºåego ÊúùÂêëÁÇ∫ x Ëª∏ÁöÑÂ±ÄÈÉ®Â∫ßÊ®ôÁ≥ª\n",
    "                cos_heading = np.cos(ego_heading)\n",
    "                sin_heading = np.sin(ego_heading)\n",
    "                \n",
    "                # ÊóãËΩâËÆäÊèõÔºöÂ∞áÂÖ®Â±ÄÂ∫ßÊ®ôËΩâÊèõÁÇ∫Â±ÄÈÉ®Â∫ßÊ®ô\n",
    "                local_x = cos_heading * dx + sin_heading * dy\n",
    "                local_y = -sin_heading * dx + cos_heading * dy\n",
    "                \n",
    "                positions.append([local_x, local_y])\n",
    "                \n",
    "            except Exception as e:\n",
    "                continue\n",
    "        \n",
    "        return np.array(positions)\n",
    "        \n",
    "    except Exception as e:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c056de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization configurations\n",
    "VISUALIZATION_COLORS: Dict[int, str] = {\n",
    "    0: \"#D10808\",  # red\n",
    "    1: \"#000000\",  # black\n",
    "    2: \"#2ECC71\",  # green\n",
    "    3: \"#E38C47\",  # orange\n",
    "    4: \"#8E44AD\",  # purple\n",
    "}\n",
    "\n",
    "TRAJECTORY_PLOT_CONFIG = {\n",
    "    \"fill_color\": VISUALIZATION_COLORS[0],\n",
    "    \"fill_color_alpha\": 1.0,\n",
    "    \"line_color\": VISUALIZATION_COLORS[0],\n",
    "    \"line_color_alpha\": 1.0,\n",
    "    \"line_width\": 0.3,\n",
    "    \"line_style\": \"-\",\n",
    "    \"zorder\": 3,\n",
    "}\n",
    "\n",
    "DRIVING_COMMAND_LABELS = [\"LEFT\", \"STRAIGHT\", \"RIGHT\", \"UNKNOWN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6b4470",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_trajectory_to_bev_ax_custom(ax: plt.Axes, trajectory: np.ndarray, config: Dict[str, Any], show_waypoints: bool = False) -> plt.Axes:\n",
    "    \"\"\"Add trajectory to BEV plot with custom styling\"\"\"\n",
    "    poses = np.concatenate([np.array([[0, 0]]), trajectory[:, :2]])\n",
    "    \n",
    "    # Áï´ËªåË∑°Á∑ö\n",
    "    ax.plot(\n",
    "        poses[:, 1],  # y coordinates\n",
    "        poses[:, 0],  # x coordinates \n",
    "        color=config[\"line_color\"],\n",
    "        alpha=config[\"line_color_alpha\"],\n",
    "        linewidth=config[\"line_width\"], \n",
    "        linestyle=config[\"line_style\"],\n",
    "        zorder=config[\"zorder\"],\n",
    "    )\n",
    "    \n",
    "    # Â¶ÇÊûúÈúÄË¶ÅÔºåÈ°ØÁ§∫ waypoints\n",
    "    if show_waypoints and len(poses) > 1:\n",
    "        ax.scatter(\n",
    "            poses[1:, 1],  # y coordinates (Ë∑≥ÈÅéËµ∑ÂßãÈªû)\n",
    "            poses[1:, 0],  # x coordinates (Ë∑≥ÈÅéËµ∑ÂßãÈªû)\n",
    "            color=config[\"line_color\"],\n",
    "            alpha=config[\"line_color_alpha\"],\n",
    "            s=20,  # marker size\n",
    "            zorder=config[\"zorder\"] + 1,\n",
    "            marker='o'\n",
    "        )\n",
    "    \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98eb52ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bev_visualization(scene_loader, token: str, evaluation_results: pd.DataFrame, \n",
    "                          sorted_trajectories: np.ndarray, sorted_weights: np.ndarray, \n",
    "                          predict_trajectory, save_path: str, title_ground_truth: str, stage_one: bool = True): \n",
    "    \n",
    "    scene = scene_loader.get_scene_from_token(token)\n",
    "    \n",
    "    if stage_one:\n",
    "        scene_for_ground_truth = scene\n",
    "        map_for_visualization = scene.map_api\n",
    "        frame_idx_for_prediction = scene.scene_metadata.num_history_frames - 1\n",
    "    else:\n",
    "        original_scene = scene_loader.get_scene_from_token(scene.scene_metadata.corresponding_original_initial_token)\n",
    "        scene_for_ground_truth = original_scene\n",
    "        map_for_visualization = scene.map_api  # ÊâÄÊúâÂ≠êÂúñÈÉΩÁî® Stage 2 Â†¥ÊôØÁöÑÂú∞Âúñ\n",
    "        frame_idx_for_prediction = scene.scene_metadata.num_history_frames - 1\n",
    "    \n",
    "    ground_truth_trajectory = scene_for_ground_truth.get_future_trajectory()\n",
    "    \n",
    "    # Create subplot figure\n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(20, 20))\n",
    "    \n",
    "    # -1. Score and Metrics Info\n",
    "    token_results = evaluation_results[evaluation_results['token'] == token].iloc[0]\n",
    "    metrics_info = '\\n'.join([f\"{col}: {value:.4f}\" if isinstance(value, float) else f\"{col}: {value}\" \n",
    "                             for col, value in token_results.items()])\n",
    "    \n",
    "    # Get driving command\n",
    "    driving_command_idx = scene.get_agent_input().ego_statuses[-1].driving_command.argmax()\n",
    "    driving_command = DRIVING_COMMAND_LABELS[driving_command_idx]\n",
    "    metrics_info += f\"\\nDriving Command: {driving_command}\"\n",
    "    \n",
    "    # Add metrics text\n",
    "    plt.figtext(0.01, 1, metrics_info, wrap=True, horizontalalignment='left', \n",
    "                fontsize=10, color='black', verticalalignment='top')\n",
    "    \n",
    "    # 0. File name\n",
    "    scene_token = scene.scene_metadata.scene_token\n",
    "    current_frame_idx = scene.scene_metadata.num_history_frames - 1\n",
    "    current_frame = scene.frames[current_frame_idx]\n",
    "    timestamp = current_frame.timestamp\n",
    "    \n",
    "    if stage_one:\n",
    "        meaningful_filename = f\"{scene_token}_{timestamp}_{token}\"\n",
    "    else:\n",
    "        original_token = scene.scene_metadata.corresponding_original_initial_token\n",
    "        meaningful_filename = f\"{original_token}_{token}\"\n",
    "        \n",
    "\n",
    "    ego_progress_col = None\n",
    "    for col in token_results.index:\n",
    "        if 'ego_progress' in col:\n",
    "            ego_progress_col = col\n",
    "            break\n",
    "    if ego_progress_col and token_results[ego_progress_col] < 0.5:\n",
    "        meaningful_filename += \"_LOW_EP\"  # Add special marker for low ego progress\n",
    "\n",
    "    # 1. Ground Truth BEV\n",
    "    add_configured_bev_on_ax(ax1, map_for_visualization, scene.frames[frame_idx_for_prediction])\n",
    "    \n",
    "    if stage_one:\n",
    "        add_trajectory_to_bev_ax(ax1, ground_truth_trajectory, TRAJECTORY_CONFIG[\"human\"])\n",
    "    else: \n",
    "        stage2_reference_traj = get_stage2_reference_trajectory(scene_loader, token)\n",
    "        if stage2_reference_traj is not None:\n",
    "            add_trajectory_to_bev_ax_custom(ax1, stage2_reference_traj, TRAJECTORY_CONFIG[\"human\"], show_waypoints=True)\n",
    "        else: \n",
    "            ax1.text(0.5, 0.5, 'No Reference Trajectory\\nAvailable for Stage 2', \n",
    "                    transform=ax1.transAxes, ha='center', va='center',\n",
    "                    fontsize=12, color='red', weight='bold')\n",
    "    \n",
    "    configure_bev_ax(ax1)\n",
    "    configure_ax(ax1)\n",
    "    if not stage_one:\n",
    "        ax1.set_title(f\"{title_ground_truth}\\n(Green: Stage2 Reference Trajectory - For Scoring)\")\n",
    "    else:\n",
    "        ax1.set_title(title_ground_truth)\n",
    "\n",
    "    # 2. Top 300 Predicted Trajectories\n",
    "    add_configured_bev_on_ax(ax2, map_for_visualization, scene.frames[frame_idx_for_prediction])\n",
    "    \n",
    "    # Plot trajectories outside top 300 with black color first (background)\n",
    "    config_black = TRAJECTORY_PLOT_CONFIG.copy()\n",
    "    config_black['line_color'] = VISUALIZATION_COLORS[1]  # black\n",
    "    config_black['line_color_alpha'] = 0.1  # very light\n",
    "    for i, trajectory in enumerate(sorted_trajectories[300:]):\n",
    "        add_trajectory_to_bev_ax_custom(ax2, trajectory, config_black)\n",
    "    \n",
    "    # Plot trajectories in tiers (top 300 only)\n",
    "    if len(sorted_trajectories) > 200:\n",
    "        config_tier3 = TRAJECTORY_PLOT_CONFIG.copy()\n",
    "        config_tier3['line_color'] = VISUALIZATION_COLORS[4]  # purple\n",
    "        for i, trajectory in enumerate(sorted_trajectories[200:300]):\n",
    "            config_tier3['line_color_alpha'] = sorted_weights[200 + i] if 200 + i < len(sorted_weights) else 0.3\n",
    "            add_trajectory_to_bev_ax_custom(ax2, trajectory, config_tier3)\n",
    "    \n",
    "    if len(sorted_trajectories) > 100:\n",
    "        config_tier2 = TRAJECTORY_PLOT_CONFIG.copy()\n",
    "        config_tier2['line_color'] = VISUALIZATION_COLORS[2]  # green\n",
    "        for i, trajectory in enumerate(sorted_trajectories[100:200]):\n",
    "            config_tier2['line_color_alpha'] = sorted_weights[100 + i] if 100 + i < len(sorted_weights) else 0.5\n",
    "            add_trajectory_to_bev_ax_custom(ax2, trajectory, config_tier2)\n",
    "    \n",
    "    config_tier1 = TRAJECTORY_PLOT_CONFIG.copy()\n",
    "    config_tier1['line_color'] = VISUALIZATION_COLORS[0]  # red\n",
    "    for i, trajectory in enumerate(sorted_trajectories[:100]):\n",
    "        config_tier1['line_color_alpha'] = sorted_weights[i] if i < len(sorted_weights) else 0.7\n",
    "        add_trajectory_to_bev_ax_custom(ax2, trajectory, config_tier1)\n",
    "    \n",
    "    configure_bev_ax(ax2)\n",
    "    configure_ax(ax2)\n",
    "    total_trajs = len(sorted_trajectories)\n",
    "    ax2.set_title(f'All {total_trajs} Trajectories (Red: 1-100, Green: 101-200, Purple: 201-300, Black: 301+)')\n",
    "\n",
    "    # 3. Top 100 Trajectories Only\n",
    "    add_configured_bev_on_ax(ax3, map_for_visualization, scene.frames[frame_idx_for_prediction])\n",
    "    config_top100 = TRAJECTORY_PLOT_CONFIG.copy()\n",
    "    config_top100['line_color'] = VISUALIZATION_COLORS[0]\n",
    "    \n",
    "    for i, trajectory in enumerate(sorted_trajectories[:100]):\n",
    "        config_top100['line_color_alpha'] = sorted_weights[i] if i < len(sorted_weights) else 0.5\n",
    "        add_trajectory_to_bev_ax_custom(ax3, trajectory, config_top100)\n",
    "    \n",
    "    configure_bev_ax(ax3)\n",
    "    configure_ax(ax3)\n",
    "    ax3.set_title(\"Top 100 Trajectories\")\n",
    "\n",
    "    # 4. Best Prediction Only\n",
    "    add_configured_bev_on_ax(ax4, map_for_visualization, scene.frames[frame_idx_for_prediction])\n",
    "    if len(sorted_trajectories) > 0:\n",
    "        add_trajectory_to_bev_ax(ax4, predict_trajectory, TRAJECTORY_CONFIG[\"agent\"])\n",
    "    configure_bev_ax(ax4)\n",
    "    configure_ax(ax4)\n",
    "    ax4.set_title(\"Best GTRS Dense Prediction\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save the plot with meaningful filename\n",
    "    if save_path:\n",
    "        os.makedirs(save_path, exist_ok=True)\n",
    "        full_filename = f\"{meaningful_filename}.png\"\n",
    "        plt.savefig(f\"{save_path}/{full_filename}\", bbox_inches='tight', dpi=300)\n",
    "        print(f\"üéØ Saved visualization {save_path}/{full_filename}\")\n",
    "        \n",
    "    plt.close()  # Close to save memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a5ef51",
   "metadata": {},
   "source": [
    "## Main function to save all visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f586bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up environment...\n",
      "Environment variables set successfully\n"
     ]
    }
   ],
   "source": [
    "print(\"Setting up environment...\")\n",
    "setup_environment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd088eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'load_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading data...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m (navhard_scene_loader, gtrs_dense_model_predictions, trajectory_vocabulary, \n\u001b[0;32m----> 3\u001b[0m     evaluation_results_df, submission_predictions) \u001b[38;5;241m=\u001b[39m \u001b[43mload_data\u001b[49m()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'load_data' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Loading data...\")\n",
    "(navhard_scene_loader, gtrs_dense_model_predictions, trajectory_vocabulary, \n",
    "    evaluation_results_df, submission_predictions) = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c00aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test: quick print\n",
    "\n",
    "print(submission_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b80a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract tokens for different stages\n",
    "stage_one_tokens = list(submission_predictions['first_stage_predictions'][0].keys())\n",
    "stage_two_tokens = list(submission_predictions['second_stage_predictions'][0].keys())\n",
    "    \n",
    "# Extract stage-specific results\n",
    "stage_one_metric_columns = [col for col in evaluation_results_df.columns if 'stage_one' in col]\n",
    "stage_one_results = evaluation_results_df[['token', 'valid', 'score'] + stage_one_metric_columns]\n",
    "stage_one_results = stage_one_results[stage_one_results['token'].isin(stage_one_tokens)]\n",
    "    \n",
    "stage_two_metric_columns = [col for col in evaluation_results_df.columns if 'stage_two' in col]\n",
    "stage_two_results = evaluation_results_df[['token', 'valid', 'score'] + stage_two_metric_columns]\n",
    "stage_two_results = stage_two_results[stage_two_results['token'].isin(stage_two_tokens)]\n",
    "\n",
    "print(f'stage one result: {stage_one_results}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d625188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick print, test\n",
    "print(stage_one_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbd9c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find worse case (EC, EP)\n",
    "stage_one_worse_conditions = (\n",
    "    (stage_one_results['ego_progress_stage_one'] <= 1)\n",
    ")\n",
    "\n",
    "stage_two_worse_conditions = (\n",
    "    (stage_two_results['ego_progress_stage_two'] <= 1)\n",
    ")\n",
    "\n",
    "# Find worse case score tokens\n",
    "stage_one_worse_case_tokens = list(stage_one_results[stage_one_worse_conditions]['token'])\n",
    "stage_two_worse_case_tokens = list(stage_two_results[stage_two_worse_conditions]['token'])\n",
    "\n",
    "print(f\"Found {len(stage_one_worse_case_tokens)} worse_case_tokens for stage 1\")\n",
    "print(f\"Found {len(stage_two_worse_case_tokens)} worse_case_tokens for stage 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1af729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick print, test\n",
    "print(stage_one_worse_case_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cf603b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick print, test\n",
    "from pprint import pprint\n",
    "scene = navhard_scene_loader.get_scene_from_token('d45f18da371a5fe5')\n",
    "pprint(scene.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8bb39c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save visualizations for each category\n",
    "\n",
    "# Stage 1 - Worse  case\n",
    "print(\"\\nSaving Stage 1 worse case visualizations...\")\n",
    "for i, token in enumerate(stage_one_worse_case_tokens):\n",
    "    try:\n",
    "        sorted_trajectories, sorted_weights = get_trajectory_predictions_for_token(\n",
    "            token, trajectory_vocabulary, gtrs_dense_model_predictions)\n",
    "            \n",
    "        plot_bev_visualization(\n",
    "            scene_loader=navhard_scene_loader,\n",
    "            token=token,\n",
    "            evaluation_results=stage_one_results,\n",
    "            sorted_trajectories=sorted_trajectories,\n",
    "            sorted_weights=sorted_weights,\n",
    "            predict_trajectory=gtrs_dense_model_predictions[token]['trajectory'],\n",
    "            save_path='new_output/stage_one_worse_case',\n",
    "            title_ground_truth=\"Human Trajectory (Stage 1)\",\n",
    "            stage_one=True\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to save visualization for token {token}: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77558f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 2 - Worse  case\n",
    "print(\"\\nSaving Stage 2 worse case visualizations...\")\n",
    "for i, token in enumerate(stage_two_worse_case_tokens):\n",
    "    try:\n",
    "        sorted_trajectories, sorted_weights = get_trajectory_predictions_for_token(\n",
    "            token, trajectory_vocabulary, gtrs_dense_model_predictions)\n",
    "            \n",
    "        plot_bev_visualization(\n",
    "            scene_loader=navhard_scene_loader,\n",
    "            token=token,\n",
    "            evaluation_results=stage_two_results,\n",
    "            sorted_trajectories=sorted_trajectories,\n",
    "            sorted_weights=sorted_weights,\n",
    "            predict_trajectory=gtrs_dense_model_predictions[token]['trajectory'],\n",
    "            save_path='new_output/stage_two_worse_case',\n",
    "            title_ground_truth=\"Corresponding Scene (Stage 2)\",\n",
    "            stage_one=False\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to save visualization for token {token}: {str(e)}\")\n",
    "    \n",
    "    \n",
    "print(\"\\n‚úÖ All visualizations saved successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "navsim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
