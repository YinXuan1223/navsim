{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19eaca7b",
   "metadata": {},
   "source": [
    "## 記錄"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b7a26f",
   "metadata": {},
   "source": [
    "目前進度：\n",
    "1. 正常讓 code 跑起來。\n",
    "2. 修改 filter，讓所有 frame 輸出。\n",
    "3. 處理 stage 2 ground truth 的問題。\n",
    "4. 加一個 python 檔，讓他可以幫我們把連續的 frame 放在同一個資料夾。\n",
    "5. 計算 ground truth 的 pdm score ** comfort\n",
    "\n",
    "待辦事項：\n",
    "1. 看靠近 ground truth 的路線的分數"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c1e64d",
   "metadata": {},
   "source": [
    "## Import and Def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75bd683e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Script to save BEV visualizations for different token categories\n",
    "Based on the analysis from plot_result.ipynb\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "import hydra\n",
    "from hydra.utils import instantiate\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from typing import Any, Dict, List, Tuple\n",
    "from tqdm import tqdm\n",
    "import lzma\n",
    "# Add the GTRS root to path\n",
    "sys.path.append('/mnt/hdd5/Qiaoceng/navsim_workspace/GTRS')\n",
    "\n",
    "from navsim.common.dataloader import SceneLoader\n",
    "from navsim.common.dataclasses import SceneFilter, SensorConfig\n",
    "from nuplan.common.actor_state.state_representation import TimePoint\n",
    "from navsim.visualization.bev import add_configured_bev_on_ax, add_trajectory_to_bev_ax\n",
    "from navsim.visualization.plots import configure_bev_ax, configure_ax\n",
    "from navsim.visualization.config import TRAJECTORY_CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c66d2ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_environment():\n",
    "    \"\"\"Set up environment variables and load configurations\"\"\"\n",
    "    # Set environment variables explicitly\n",
    "    os.environ[\"NUPLAN_MAPS_ROOT\"] = \"/mnt/hdd8/navsim_dataset/maps\"\n",
    "    os.environ[\"NUPLAN_MAP_VERSION\"] = \"nuplan-maps-v1.0\"\n",
    "    os.environ[\"NUPLAN_DATA_STORE\"] = \"local\"\n",
    "    os.environ[\"OPENSCENE_DATA_ROOT\"] = \"/mnt/hdd8/navsim_dataset\"\n",
    "    os.environ[\"NAVSIM_EXP_ROOT\"] = \"/mnt/hdd5/Qiaoceng/navsim_workspace/exp\"\n",
    "    os.environ[\"NAVSIM_DEVKIT_ROOT\"] = \"/mnt/hdd5/Qiaoceng/navsim_workspace/GTRS\"\n",
    "\n",
    "    load_dotenv(override=True)\n",
    "    \n",
    "    print(\"Environment variables set successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28a708c",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3485938061.py, line 27)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[3], line 27\u001b[0;36m\u001b[0m\n\u001b[0;31m    /mnt/hdd8/navsim_dataset/navhard_two_stage/sensor_blobs,\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def load_data():\n",
    "    \"\"\"Load all required data and configurations\"\"\"\n",
    "    \n",
    "    # Also set the nuplan constants directly\n",
    "    import nuplan.common.maps.nuplan_map.map_factory as map_factory\n",
    "    map_factory.NUPLAN_MAPS_ROOT = \"/mnt/hdd8/navsim_dataset/maps\"\n",
    "    \n",
    "    # Print for debugging\n",
    "    print(f\"NUPLAN_MAPS_ROOT: {os.environ.get('NUPLAN_MAPS_ROOT')}\")\n",
    "    print(f\"OPENSCENE_DATA_ROOT: {os.environ.get('OPENSCENE_DATA_ROOT')}\")\n",
    "    \n",
    "    # Constants for data configuration\n",
    "    DATA_SPLIT = \"test\"\n",
    "    SCENE_FILTER_NAME = \"navhard_two_stage\"\n",
    "    \n",
    "    # Initialize Hydra configuration for scene filtering\n",
    "    hydra.initialize(config_path=\"../navsim/planning/script/config/common/train_test_split/scene_filter\", version_base=None)\n",
    "    scene_filter_config = hydra.compose(config_name=SCENE_FILTER_NAME)\n",
    "    scene_filter: SceneFilter = instantiate(scene_filter_config)\n",
    "    \n",
    "    # Setup data paths\n",
    "    openscene_data_root = Path(os.getenv(\"OPENSCENE_DATA_ROOT\"))\n",
    "    navhard_scene_loader = SceneLoader(\n",
    "        openscene_data_root / f\"navsim_logs/{DATA_SPLIT}\",\n",
    "        openscene_data_root / f\"sensor_blobs/{DATA_SPLIT}\",\n",
    "        scene_filter,\n",
    "        \"/mnt/hdd8/navsim_dataset/navhard_two_stage/sensor_blobs\",\n",
    "        \"/mnt/hdd8/navsim_dataset/navhard_two_stage/synthetic_scene_pickles\",\n",
    "        sensor_config=SensorConfig.build_no_sensors(),\n",
    "    )\n",
    "    \n",
    "    # Load GTRS Dense model predictions\n",
    "    gtrs_dense_model_path = '/mnt/hdd5/Qiaoceng/navsim_workspace/model/GTRS/epoch19_navhard.pkl'\n",
    "    with open(gtrs_dense_model_path, 'rb') as f:\n",
    "        gtrs_dense_model_predictions = pickle.load(f)\n",
    "    \n",
    "    # Load trajectory vocabulary\n",
    "    trajectory_vocab_path = '/mnt/hdd5/Qiaoceng/navsim_workspace/GTRS/traj_final/8192.npy'\n",
    "    trajectory_vocabulary = np.load(trajectory_vocab_path)\n",
    "    \n",
    "    # Load evaluation results\n",
    "    evaluation_results_path = \"/mnt/hdd5/Qiaoceng/navsim_workspace/exp/train_gtrs_dense/2025.08.21.17.44.36/2025.08.21.18.36.35.csv\"\n",
    "    evaluation_results_df = pd.read_csv(evaluation_results_path)\n",
    "    \n",
    "    # Load submission file\n",
    "    submission_file_path = \"/mnt/hdd5/Qiaoceng/navsim_workspace/model/GTRS/submission_gtrs_dense.pkl\"\n",
    "    with open(submission_file_path, \"rb\") as f:\n",
    "        submission_predictions = pickle.load(f)\n",
    "    \n",
    "    return (navhard_scene_loader, gtrs_dense_model_predictions, trajectory_vocabulary, \n",
    "            evaluation_results_df, submission_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb1825d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_scores(result):\n",
    "    \"\"\"Calculate trajectory scores\"\"\"\n",
    "    time_to_collision_within_bound = np.exp(result['time_to_collision_within_bound'])\n",
    "    ego_progress = np.exp(result['ego_progress'])\n",
    "    lane_keeping = np.exp(result['lane_keeping'])\n",
    "    scores = (\n",
    "        0.01 * result['imi'] +\n",
    "        0.1 * result['traffic_light_compliance'] +\n",
    "        0.5 * result['no_at_fault_collisions'] +\n",
    "        0.5 * result['drivable_area_compliance'] +\n",
    "        0.5 * result['driving_direction_compliance'] +\n",
    "        3.0 * np.log(5.0 * time_to_collision_within_bound +\n",
    "                    5.0 * ego_progress +\n",
    "                    2.0 * lane_keeping)\n",
    "    )\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dca58e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_score(scores):\n",
    "    \"\"\"Normalize trajectory scores\"\"\"\n",
    "    scores = np.where(np.isfinite(scores), scores, np.nan)\n",
    "    if np.all(np.isnan(scores)):\n",
    "        return np.zeros_like(scores)\n",
    "    min_score = np.nanmin(scores)\n",
    "    max_score = np.nanmax(scores)\n",
    "    if max_score == min_score:\n",
    "        return np.zeros_like(scores)\n",
    "    norm = (scores - min_score) / (max_score - min_score)\n",
    "    norm = np.nan_to_num(norm, nan=0.0)\n",
    "    return norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8def4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trajectory_predictions_for_token(token: str, trajectory_vocabulary, gtrs_dense_model_predictions) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"Get sorted trajectory predictions for a token\"\"\"\n",
    "    total_trajectory = np.concatenate((trajectory_vocabulary, gtrs_dense_model_predictions[token]['interpolated_proposal']), axis=0)\n",
    "    \n",
    "    scores = calculate_scores(gtrs_dense_model_predictions[token])\n",
    "    weights = normalize_score(scores)\n",
    "    sorted_indices = np.argsort(weights)[::-1]\n",
    "    sorted_trajectories = total_trajectory[sorted_indices]\n",
    "    sorted_weights = weights[sorted_indices]\n",
    "    \n",
    "    return sorted_trajectories, sorted_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09a6cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function for 1. Stage 2 reference trajectory\n",
    "\n",
    "def get_stage2_reference_trajectory(scene_loader, token: str):\n",
    "    try:\n",
    "        scene = scene_loader.get_scene_from_token(token)\n",
    "        \n",
    "        # Determine if it is Stage 2 - if there is corresponding_original_initial_token, it is Stage 2\n",
    "        if not hasattr(scene.scene_metadata, 'corresponding_original_initial_token') or \\\n",
    "           scene.scene_metadata.corresponding_original_initial_token is None:\n",
    "            return None \n",
    "            \n",
    "        log_name = scene.scene_metadata.log_name\n",
    "        timestamp = scene.frames[scene.scene_metadata.num_history_frames - 1].timestamp\n",
    "\n",
    "        ## Extract reference trajectory from metric cache\n",
    "        # Construct metric cache path - use more precise search\n",
    "        stage2_cache_path = Path('/mnt/hdd5/Qiaoceng/navsim_workspace/exp/metric_cache_stage_2')\n",
    "        \n",
    "        # Search for corresponding cache file - match using log_name\n",
    "        cache_file = None\n",
    "        for scene_dir in stage2_cache_path.iterdir():\n",
    "            if scene_dir.is_dir() and log_name in scene_dir.name:\n",
    "                for sub_dir in scene_dir.rglob('*'):\n",
    "                    if sub_dir.is_dir():\n",
    "                        pkl_file = sub_dir / 'metric_cache.pkl'\n",
    "                        if pkl_file.exists():\n",
    "                            try:  # Validate if it is the correct cache\n",
    "                                with lzma.open(pkl_file, 'rb') as f:\n",
    "                                    metric_cache = pickle.load(f)\n",
    "                                if (hasattr(metric_cache, 'log_name') and  # Check if log_name and timestamp match\n",
    "                                    metric_cache.log_name == log_name and\n",
    "                                    hasattr(metric_cache, 'timepoint')):\n",
    "                                    # Simple time matching check\n",
    "                                    cache_time = metric_cache.timepoint.time_s\n",
    "                                    scene_time = timestamp / 1e6  # Convert to seconds\n",
    "                                    if abs(cache_time - scene_time) < 1.0:  # 1 second tolerance\n",
    "                                        cache_file = pkl_file\n",
    "                                        break\n",
    "                            except:\n",
    "                                continue\n",
    "                if cache_file:\n",
    "                    break\n",
    "        \n",
    "        if not cache_file:\n",
    "            print(f\"No corresponding cache file found for token: {token}\")\n",
    "            return None\n",
    "            \n",
    "        # 讀取並處理軌跡\n",
    "        with lzma.open(cache_file, 'rb') as f:\n",
    "            metric_cache = pickle.load(f)\n",
    "        \n",
    "        traj = metric_cache.trajectory\n",
    "        if not traj:\n",
    "            return None\n",
    "        \n",
    "        # 採樣軌跡點 - 從當前時間點開始採樣\n",
    "        start_time_us = traj.start_time.time_us\n",
    "        end_time_us = traj.end_time.time_us\n",
    "        current_time_us = timestamp * 1e6\n",
    "        \n",
    "        # 找到與當前場景時間最接近的軌跡起始點\n",
    "        search_range_us = 2.0 * 1e6  # 搜索範圍：前後2秒\n",
    "        search_start = max(start_time_us, current_time_us - search_range_us)\n",
    "        search_end = min(end_time_us, current_time_us + search_range_us)\n",
    "        \n",
    "        min_time_diff = float('inf')\n",
    "        best_start_time_us = None\n",
    "        \n",
    "        for test_time_us in range(int(search_start), int(search_end), int(0.1 * 1e6)):\n",
    "            time_diff = abs(test_time_us - current_time_us)\n",
    "            if time_diff < min_time_diff:\n",
    "                min_time_diff = time_diff\n",
    "                best_start_time_us = test_time_us\n",
    "        \n",
    "        if best_start_time_us is None:\n",
    "            best_start_time_us = start_time_us\n",
    "        \n",
    "        # 每 0.5 秒採樣一次，總共 4 秒（8個點）\n",
    "        sample_interval_us = int(0.5 * 1e6)\n",
    "        \n",
    "        time_points = []\n",
    "        for i in range(8):  # 8個點\n",
    "            time_us = best_start_time_us + i * sample_interval_us\n",
    "            if time_us <= end_time_us:\n",
    "                time_points.append(TimePoint(time_us))\n",
    "            else:\n",
    "                break\n",
    "        \n",
    "        # 獲取每個時間點的狀態\n",
    "        states = []\n",
    "        for time_point in time_points:\n",
    "            try:\n",
    "                state = traj.get_state_at_time(time_point)\n",
    "                states.append(state)\n",
    "            except:\n",
    "                break\n",
    "        \n",
    "        if len(states) < 2:\n",
    "            return None\n",
    "            \n",
    "        # 獲取當前場景的 ego 起始位置\n",
    "        current_ego_state = scene.frames[scene.scene_metadata.num_history_frames - 1].ego_status.ego_pose\n",
    "        \n",
    "        # 獲取當前 ego 位置的 x, y, heading 坐標\n",
    "        if hasattr(current_ego_state, 'x') and hasattr(current_ego_state, 'y'):\n",
    "            ego_x, ego_y = current_ego_state.x, current_ego_state.y\n",
    "            ego_heading = current_ego_state.heading if hasattr(current_ego_state, 'heading') else 0.0\n",
    "        elif isinstance(current_ego_state, np.ndarray):\n",
    "            ego_x, ego_y = current_ego_state[0], current_ego_state[1]\n",
    "            ego_heading = current_ego_state[2] if len(current_ego_state) > 2 else 0.0\n",
    "        else:\n",
    "            ego_x, ego_y = current_ego_state[0], current_ego_state[1]\n",
    "            ego_heading = current_ego_state[2] if len(current_ego_state) > 2 else 0.0\n",
    "        \n",
    "        # 轉換為相對於當前 ego 位置的軌跡（局部座標系）\n",
    "        positions = []\n",
    "        for i, state in enumerate(states):\n",
    "            try:\n",
    "                # 獲取軌跡點的絕對座標\n",
    "                if hasattr(state, 'rear_axle') and hasattr(state.rear_axle, 'x'):\n",
    "                    traj_x = state.rear_axle.x\n",
    "                    traj_y = state.rear_axle.y\n",
    "                elif hasattr(state, 'x') and hasattr(state, 'y'):\n",
    "                    traj_x = state.x\n",
    "                    traj_y = state.y\n",
    "                elif isinstance(state, np.ndarray):\n",
    "                    traj_x = state[0]\n",
    "                    traj_y = state[1]\n",
    "                else:\n",
    "                    continue\n",
    "                \n",
    "                # 計算相對於 ego 的偏移（全局座標系）\n",
    "                dx = traj_x - ego_x\n",
    "                dy = traj_y - ego_y\n",
    "                \n",
    "                # 轉換到以 ego 為原點，ego 朝向為 x 軸的局部座標系\n",
    "                cos_heading = np.cos(ego_heading)\n",
    "                sin_heading = np.sin(ego_heading)\n",
    "                \n",
    "                # 旋轉變換：將全局座標轉換為局部座標\n",
    "                local_x = cos_heading * dx + sin_heading * dy\n",
    "                local_y = -sin_heading * dx + cos_heading * dy\n",
    "                \n",
    "                positions.append([local_x, local_y])\n",
    "                \n",
    "            except Exception as e:\n",
    "                continue\n",
    "        \n",
    "        return np.array(positions)\n",
    "        \n",
    "    except Exception as e:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c056de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization configurations\n",
    "VISUALIZATION_COLORS: Dict[int, str] = {\n",
    "    0: \"#D10808\",  # red\n",
    "    1: \"#000000\",  # black\n",
    "    2: \"#2ECC71\",  # green\n",
    "    3: \"#E38C47\",  # orange\n",
    "    4: \"#8E44AD\",  # purple\n",
    "}\n",
    "\n",
    "TRAJECTORY_PLOT_CONFIG = {\n",
    "    \"fill_color\": VISUALIZATION_COLORS[0],\n",
    "    \"fill_color_alpha\": 1.0,\n",
    "    \"line_color\": VISUALIZATION_COLORS[0],\n",
    "    \"line_color_alpha\": 1.0,\n",
    "    \"line_width\": 0.3,\n",
    "    \"line_style\": \"-\",\n",
    "    \"zorder\": 3,\n",
    "}\n",
    "\n",
    "DRIVING_COMMAND_LABELS = [\"LEFT\", \"STRAIGHT\", \"RIGHT\", \"UNKNOWN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6b4470",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_trajectory_to_bev_ax_custom(ax: plt.Axes, trajectory: np.ndarray, config: Dict[str, Any], show_waypoints: bool = False) -> plt.Axes:\n",
    "    \"\"\"Add trajectory to BEV plot with custom styling\"\"\"\n",
    "    poses = np.concatenate([np.array([[0, 0]]), trajectory[:, :2]])\n",
    "    \n",
    "    # 畫軌跡線\n",
    "    ax.plot(\n",
    "        poses[:, 1],  # y coordinates\n",
    "        poses[:, 0],  # x coordinates \n",
    "        color=config[\"line_color\"],\n",
    "        alpha=config[\"line_color_alpha\"],\n",
    "        linewidth=config[\"line_width\"], \n",
    "        linestyle=config[\"line_style\"],\n",
    "        zorder=config[\"zorder\"],\n",
    "    )\n",
    "    \n",
    "    # 如果需要，顯示 waypoints\n",
    "    if show_waypoints and len(poses) > 1:\n",
    "        ax.scatter(\n",
    "            poses[1:, 1],  # y coordinates (跳過起始點)\n",
    "            poses[1:, 0],  # x coordinates (跳過起始點)\n",
    "            color=config[\"line_color\"],\n",
    "            alpha=config[\"line_color_alpha\"],\n",
    "            s=20,  # marker size\n",
    "            zorder=config[\"zorder\"] + 1,\n",
    "            marker='o'\n",
    "        )\n",
    "    \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98eb52ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bev_visualization(scene_loader, token: str, evaluation_results: pd.DataFrame, \n",
    "                          sorted_trajectories: np.ndarray, sorted_weights: np.ndarray, \n",
    "                          predict_trajectory, save_path: str, title_ground_truth: str, stage_one: bool = True): \n",
    "    \n",
    "    scene = scene_loader.get_scene_from_token(token)\n",
    "    \n",
    "    if stage_one:\n",
    "        scene_for_ground_truth = scene\n",
    "        map_for_visualization = scene.map_api\n",
    "        frame_idx_for_prediction = scene.scene_metadata.num_history_frames - 1\n",
    "    else:\n",
    "        original_scene = scene_loader.get_scene_from_token(scene.scene_metadata.corresponding_original_initial_token)\n",
    "        scene_for_ground_truth = original_scene\n",
    "        map_for_visualization = scene.map_api  # 所有子圖都用 Stage 2 場景的地圖\n",
    "        frame_idx_for_prediction = scene.scene_metadata.num_history_frames - 1\n",
    "    \n",
    "    ground_truth_trajectory = scene_for_ground_truth.get_future_trajectory()\n",
    "    \n",
    "    # Create subplot figure\n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(20, 20))\n",
    "    \n",
    "    # -1. Score and Metrics Info\n",
    "    token_results = evaluation_results[evaluation_results['token'] == token].iloc[0]\n",
    "    metrics_info = '\\n'.join([f\"{col}: {value:.4f}\" if isinstance(value, float) else f\"{col}: {value}\" \n",
    "                             for col, value in token_results.items()])\n",
    "    \n",
    "    # Get driving command\n",
    "    driving_command_idx = scene.get_agent_input().ego_statuses[-1].driving_command.argmax()\n",
    "    driving_command = DRIVING_COMMAND_LABELS[driving_command_idx]\n",
    "    metrics_info += f\"\\nDriving Command: {driving_command}\"\n",
    "    \n",
    "    # Add metrics text\n",
    "    plt.figtext(0.01, 1, metrics_info, wrap=True, horizontalalignment='left', \n",
    "                fontsize=10, color='black', verticalalignment='top')\n",
    "    \n",
    "    # 0. File name\n",
    "    scene_token = scene.scene_metadata.scene_token\n",
    "    current_frame_idx = scene.scene_metadata.num_history_frames - 1\n",
    "    current_frame = scene.frames[current_frame_idx]\n",
    "    timestamp = current_frame.timestamp\n",
    "    \n",
    "    if stage_one:\n",
    "        meaningful_filename = f\"{scene_token}_{timestamp}_{token}\"\n",
    "    else:\n",
    "        original_token = scene.scene_metadata.corresponding_original_initial_token\n",
    "        meaningful_filename = f\"{original_token}_{token}\"\n",
    "        \n",
    "\n",
    "    ego_progress_col = None\n",
    "    for col in token_results.index:\n",
    "        if 'ego_progress' in col:\n",
    "            ego_progress_col = col\n",
    "            break\n",
    "    if ego_progress_col and token_results[ego_progress_col] < 0.5:\n",
    "        meaningful_filename += \"_LOW_EP\"  # Add special marker for low ego progress\n",
    "\n",
    "    # 1. Ground Truth BEV\n",
    "    add_configured_bev_on_ax(ax1, map_for_visualization, scene.frames[frame_idx_for_prediction])\n",
    "    \n",
    "    if stage_one:\n",
    "        add_trajectory_to_bev_ax(ax1, ground_truth_trajectory, TRAJECTORY_CONFIG[\"human\"])\n",
    "    else: \n",
    "        stage2_reference_traj = get_stage2_reference_trajectory(scene_loader, token)\n",
    "        if stage2_reference_traj is not None:\n",
    "            add_trajectory_to_bev_ax_custom(ax1, stage2_reference_traj, TRAJECTORY_CONFIG[\"human\"], show_waypoints=True)\n",
    "        else: \n",
    "            ax1.text(0.5, 0.5, 'No Reference Trajectory\\nAvailable for Stage 2', \n",
    "                    transform=ax1.transAxes, ha='center', va='center',\n",
    "                    fontsize=12, color='red', weight='bold')\n",
    "    \n",
    "    configure_bev_ax(ax1)\n",
    "    configure_ax(ax1)\n",
    "    if not stage_one:\n",
    "        ax1.set_title(f\"{title_ground_truth}\\n(Green: Stage2 Reference Trajectory - For Scoring)\")\n",
    "    else:\n",
    "        ax1.set_title(title_ground_truth)\n",
    "\n",
    "    # 2. Top 300 Predicted Trajectories\n",
    "    add_configured_bev_on_ax(ax2, map_for_visualization, scene.frames[frame_idx_for_prediction])\n",
    "    \n",
    "    # Plot trajectories outside top 300 with black color first (background)\n",
    "    config_black = TRAJECTORY_PLOT_CONFIG.copy()\n",
    "    config_black['line_color'] = VISUALIZATION_COLORS[1]  # black\n",
    "    config_black['line_color_alpha'] = 0.1  # very light\n",
    "    for i, trajectory in enumerate(sorted_trajectories[300:]):\n",
    "        add_trajectory_to_bev_ax_custom(ax2, trajectory, config_black)\n",
    "    \n",
    "    # Plot trajectories in tiers (top 300 only)\n",
    "    if len(sorted_trajectories) > 200:\n",
    "        config_tier3 = TRAJECTORY_PLOT_CONFIG.copy()\n",
    "        config_tier3['line_color'] = VISUALIZATION_COLORS[4]  # purple\n",
    "        for i, trajectory in enumerate(sorted_trajectories[200:300]):\n",
    "            config_tier3['line_color_alpha'] = sorted_weights[200 + i] if 200 + i < len(sorted_weights) else 0.3\n",
    "            add_trajectory_to_bev_ax_custom(ax2, trajectory, config_tier3)\n",
    "    \n",
    "    if len(sorted_trajectories) > 100:\n",
    "        config_tier2 = TRAJECTORY_PLOT_CONFIG.copy()\n",
    "        config_tier2['line_color'] = VISUALIZATION_COLORS[2]  # green\n",
    "        for i, trajectory in enumerate(sorted_trajectories[100:200]):\n",
    "            config_tier2['line_color_alpha'] = sorted_weights[100 + i] if 100 + i < len(sorted_weights) else 0.5\n",
    "            add_trajectory_to_bev_ax_custom(ax2, trajectory, config_tier2)\n",
    "    \n",
    "    config_tier1 = TRAJECTORY_PLOT_CONFIG.copy()\n",
    "    config_tier1['line_color'] = VISUALIZATION_COLORS[0]  # red\n",
    "    for i, trajectory in enumerate(sorted_trajectories[:100]):\n",
    "        config_tier1['line_color_alpha'] = sorted_weights[i] if i < len(sorted_weights) else 0.7\n",
    "        add_trajectory_to_bev_ax_custom(ax2, trajectory, config_tier1)\n",
    "    \n",
    "    configure_bev_ax(ax2)\n",
    "    configure_ax(ax2)\n",
    "    total_trajs = len(sorted_trajectories)\n",
    "    ax2.set_title(f'All {total_trajs} Trajectories (Red: 1-100, Green: 101-200, Purple: 201-300, Black: 301+)')\n",
    "\n",
    "    # 3. Top 100 Trajectories Only\n",
    "    add_configured_bev_on_ax(ax3, map_for_visualization, scene.frames[frame_idx_for_prediction])\n",
    "    config_top100 = TRAJECTORY_PLOT_CONFIG.copy()\n",
    "    config_top100['line_color'] = VISUALIZATION_COLORS[0]\n",
    "    \n",
    "    for i, trajectory in enumerate(sorted_trajectories[:100]):\n",
    "        config_top100['line_color_alpha'] = sorted_weights[i] if i < len(sorted_weights) else 0.5\n",
    "        add_trajectory_to_bev_ax_custom(ax3, trajectory, config_top100)\n",
    "    \n",
    "    configure_bev_ax(ax3)\n",
    "    configure_ax(ax3)\n",
    "    ax3.set_title(\"Top 100 Trajectories\")\n",
    "\n",
    "    # 4. Best Prediction Only\n",
    "    add_configured_bev_on_ax(ax4, map_for_visualization, scene.frames[frame_idx_for_prediction])\n",
    "    if len(sorted_trajectories) > 0:\n",
    "        add_trajectory_to_bev_ax(ax4, predict_trajectory, TRAJECTORY_CONFIG[\"agent\"])\n",
    "    configure_bev_ax(ax4)\n",
    "    configure_ax(ax4)\n",
    "    ax4.set_title(\"Best GTRS Dense Prediction\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save the plot with meaningful filename\n",
    "    if save_path:\n",
    "        os.makedirs(save_path, exist_ok=True)\n",
    "        full_filename = f\"{meaningful_filename}.png\"\n",
    "        plt.savefig(f\"{save_path}/{full_filename}\", bbox_inches='tight', dpi=300)\n",
    "        print(f\"🎯 Saved visualization {save_path}/{full_filename}\")\n",
    "        \n",
    "    plt.close()  # Close to save memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a5ef51",
   "metadata": {},
   "source": [
    "## Main function to save all visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f586bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up environment...\n",
      "Environment variables set successfully\n"
     ]
    }
   ],
   "source": [
    "print(\"Setting up environment...\")\n",
    "setup_environment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd088eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'load_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading data...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m (navhard_scene_loader, gtrs_dense_model_predictions, trajectory_vocabulary, \n\u001b[0;32m----> 3\u001b[0m     evaluation_results_df, submission_predictions) \u001b[38;5;241m=\u001b[39m \u001b[43mload_data\u001b[49m()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'load_data' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Loading data...\")\n",
    "(navhard_scene_loader, gtrs_dense_model_predictions, trajectory_vocabulary, \n",
    "    evaluation_results_df, submission_predictions) = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c00aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test: quick print\n",
    "\n",
    "print(submission_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b80a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract tokens for different stages\n",
    "stage_one_tokens = list(submission_predictions['first_stage_predictions'][0].keys())\n",
    "stage_two_tokens = list(submission_predictions['second_stage_predictions'][0].keys())\n",
    "    \n",
    "# Extract stage-specific results\n",
    "stage_one_metric_columns = [col for col in evaluation_results_df.columns if 'stage_one' in col]\n",
    "stage_one_results = evaluation_results_df[['token', 'valid', 'score'] + stage_one_metric_columns]\n",
    "stage_one_results = stage_one_results[stage_one_results['token'].isin(stage_one_tokens)]\n",
    "    \n",
    "stage_two_metric_columns = [col for col in evaluation_results_df.columns if 'stage_two' in col]\n",
    "stage_two_results = evaluation_results_df[['token', 'valid', 'score'] + stage_two_metric_columns]\n",
    "stage_two_results = stage_two_results[stage_two_results['token'].isin(stage_two_tokens)]\n",
    "\n",
    "print(f'stage one result: {stage_one_results}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d625188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick print, test\n",
    "print(stage_one_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbd9c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find worse case (EC, EP)\n",
    "stage_one_worse_conditions = (\n",
    "    (stage_one_results['ego_progress_stage_one'] <= 1)\n",
    ")\n",
    "\n",
    "stage_two_worse_conditions = (\n",
    "    (stage_two_results['ego_progress_stage_two'] <= 1)\n",
    ")\n",
    "\n",
    "# Find worse case score tokens\n",
    "stage_one_worse_case_tokens = list(stage_one_results[stage_one_worse_conditions]['token'])\n",
    "stage_two_worse_case_tokens = list(stage_two_results[stage_two_worse_conditions]['token'])\n",
    "\n",
    "print(f\"Found {len(stage_one_worse_case_tokens)} worse_case_tokens for stage 1\")\n",
    "print(f\"Found {len(stage_two_worse_case_tokens)} worse_case_tokens for stage 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1af729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick print, test\n",
    "print(stage_one_worse_case_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cf603b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick print, test\n",
    "from pprint import pprint\n",
    "scene = navhard_scene_loader.get_scene_from_token('d45f18da371a5fe5')\n",
    "pprint(scene.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8bb39c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save visualizations for each category\n",
    "\n",
    "# Stage 1 - Worse  case\n",
    "print(\"\\nSaving Stage 1 worse case visualizations...\")\n",
    "for i, token in enumerate(stage_one_worse_case_tokens):\n",
    "    try:\n",
    "        sorted_trajectories, sorted_weights = get_trajectory_predictions_for_token(\n",
    "            token, trajectory_vocabulary, gtrs_dense_model_predictions)\n",
    "            \n",
    "        plot_bev_visualization(\n",
    "            scene_loader=navhard_scene_loader,\n",
    "            token=token,\n",
    "            evaluation_results=stage_one_results,\n",
    "            sorted_trajectories=sorted_trajectories,\n",
    "            sorted_weights=sorted_weights,\n",
    "            predict_trajectory=gtrs_dense_model_predictions[token]['trajectory'],\n",
    "            save_path='new_output/stage_one_worse_case',\n",
    "            title_ground_truth=\"Human Trajectory (Stage 1)\",\n",
    "            stage_one=True\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to save visualization for token {token}: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77558f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 2 - Worse  case\n",
    "print(\"\\nSaving Stage 2 worse case visualizations...\")\n",
    "for i, token in enumerate(stage_two_worse_case_tokens):\n",
    "    try:\n",
    "        sorted_trajectories, sorted_weights = get_trajectory_predictions_for_token(\n",
    "            token, trajectory_vocabulary, gtrs_dense_model_predictions)\n",
    "            \n",
    "        plot_bev_visualization(\n",
    "            scene_loader=navhard_scene_loader,\n",
    "            token=token,\n",
    "            evaluation_results=stage_two_results,\n",
    "            sorted_trajectories=sorted_trajectories,\n",
    "            sorted_weights=sorted_weights,\n",
    "            predict_trajectory=gtrs_dense_model_predictions[token]['trajectory'],\n",
    "            save_path='new_output/stage_two_worse_case',\n",
    "            title_ground_truth=\"Corresponding Scene (Stage 2)\",\n",
    "            stage_one=False\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to save visualization for token {token}: {str(e)}\")\n",
    "    \n",
    "    \n",
    "print(\"\\n✅ All visualizations saved successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "navsim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
